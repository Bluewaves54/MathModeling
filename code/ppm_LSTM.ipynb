{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports modules\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dense, InputLayer, BatchNormalization\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import format_ppm_x\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from statsmodels.tsa.seasonal import MSTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "num_features = ()\n",
    "num_prev_vals = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 1\n"
     ]
    }
   ],
   "source": [
    "data = format_ppm_x(pd.read_csv('../data/ppm.csv'), num_prev_vals)\n",
    "\n",
    "# X = np.array(data.iloc[:, data.columns != 0]).reshape(num_prev_vals*(63-num_prev_vals), 1)\n",
    "X = data.iloc[:, data.columns != 0]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "Y = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(num_prev_vals,1)))\n",
    "    # model.add(LSTM(128, activation='relu', dropout=0.05, return_sequences=True))\n",
    "    model.add(LSTM(64, activation='relu', dropout=0.05, return_sequences=True))\n",
    "    model.add(LSTM(16, activation='relu', dropout=0.05, return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 12:58:46.155845: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.3,\n",
    "    momentum=0.6,\n",
    "    nesterov=True,\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mae', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp = MSTL(Y, periods=(12))\n",
    "\n",
    "res = decomp.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'DecomposeResult' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ayushpal/Coding/MachineLearning/MathModeling/code/ppm_LSTM.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ayushpal/Coding/MachineLearning/MathModeling/code/ppm_LSTM.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mlen\u001b[39;49m(res)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'DecomposeResult' has no len()"
     ]
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "8/8 [==============================] - 2s 56ms/step - loss: 4679.5103 - mae: 4679.5103 - val_loss: nan - val_mae: nan\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 355.6835 - mae: 355.6835 - val_loss: nan - val_mae: nan\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 349.7223 - mae: 349.7223 - val_loss: nan - val_mae: nan\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 343.7229 - mae: 343.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 337.7229 - mae: 337.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 331.7229 - mae: 331.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 325.7229 - mae: 325.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 319.7229 - mae: 319.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 313.7229 - mae: 313.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 307.7229 - mae: 307.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 301.7229 - mae: 301.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 295.7229 - mae: 295.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 289.7229 - mae: 289.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 283.7229 - mae: 283.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 277.7229 - mae: 277.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 271.7229 - mae: 271.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 265.7229 - mae: 265.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 259.7229 - mae: 259.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 253.7229 - mae: 253.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 247.7229 - mae: 247.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 241.7229 - mae: 241.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 235.7229 - mae: 235.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 229.7229 - mae: 229.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 223.7229 - mae: 223.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 217.7229 - mae: 217.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 211.7229 - mae: 211.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 205.7229 - mae: 205.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 199.7229 - mae: 199.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 193.7229 - mae: 193.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 187.7229 - mae: 187.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 181.7229 - mae: 181.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 175.7229 - mae: 175.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 169.7229 - mae: 169.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 163.7229 - mae: 163.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 157.7229 - mae: 157.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 151.7229 - mae: 151.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 145.7229 - mae: 145.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 139.7229 - mae: 139.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 133.7229 - mae: 133.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 127.7229 - mae: 127.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 121.7229 - mae: 121.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 115.7229 - mae: 115.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 109.7229 - mae: 109.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 103.7229 - mae: 103.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 97.7229 - mae: 97.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 91.7229 - mae: 91.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 85.7229 - mae: 85.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 79.7229 - mae: 79.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 73.7229 - mae: 73.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 67.7229 - mae: 67.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 61.7229 - mae: 61.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 55.7229 - mae: 55.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 49.7229 - mae: 49.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43.7229 - mae: 43.7229 - val_loss: nan - val_mae: nan\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 37.8939 - mae: 37.8939 - val_loss: nan - val_mae: nan\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 33.6470 - mae: 33.6470 - val_loss: nan - val_mae: nan\n",
      "Epoch 57/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 30.6655 - mae: 30.6655 - val_loss: nan - val_mae: nan\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 28.6970 - mae: 28.6970 - val_loss: nan - val_mae: nan\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27.3108 - mae: 27.3108 - val_loss: nan - val_mae: nan\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 26.2085 - mae: 26.2085 - val_loss: nan - val_mae: nan\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 25.3746 - mae: 25.3746 - val_loss: nan - val_mae: nan\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 24.9182 - mae: 24.9182 - val_loss: nan - val_mae: nan\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 24.5476 - mae: 24.5476 - val_loss: nan - val_mae: nan\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 24.2290 - mae: 24.2290 - val_loss: nan - val_mae: nan\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.9997 - mae: 23.9997 - val_loss: nan - val_mae: nan\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.8136 - mae: 23.8136 - val_loss: nan - val_mae: nan\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.6583 - mae: 23.6583 - val_loss: nan - val_mae: nan\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.6155 - mae: 23.6155 - val_loss: nan - val_mae: nan\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.5527 - mae: 23.5527 - val_loss: nan - val_mae: nan\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4777 - mae: 23.4777 - val_loss: nan - val_mae: nan\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.5003 - mae: 23.5003 - val_loss: nan - val_mae: nan\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.4031 - mae: 23.4031 - val_loss: nan - val_mae: nan\n",
      "Epoch 73/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4229 - mae: 23.4229 - val_loss: nan - val_mae: nan\n",
      "Epoch 74/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4352 - mae: 23.4352 - val_loss: nan - val_mae: nan\n",
      "Epoch 75/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3966 - mae: 23.3966 - val_loss: nan - val_mae: nan\n",
      "Epoch 76/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4088 - mae: 23.4088 - val_loss: nan - val_mae: nan\n",
      "Epoch 77/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3883 - mae: 23.3883 - val_loss: nan - val_mae: nan\n",
      "Epoch 78/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3612 - mae: 23.3612 - val_loss: nan - val_mae: nan\n",
      "Epoch 79/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3637 - mae: 23.3637 - val_loss: nan - val_mae: nan\n",
      "Epoch 80/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3974 - mae: 23.3974 - val_loss: nan - val_mae: nan\n",
      "Epoch 81/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3946 - mae: 23.3946 - val_loss: nan - val_mae: nan\n",
      "Epoch 82/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3779 - mae: 23.3779 - val_loss: nan - val_mae: nan\n",
      "Epoch 83/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3380 - mae: 23.3380 - val_loss: nan - val_mae: nan\n",
      "Epoch 84/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4213 - mae: 23.4213 - val_loss: nan - val_mae: nan\n",
      "Epoch 85/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4029 - mae: 23.4029 - val_loss: nan - val_mae: nan\n",
      "Epoch 86/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4202 - mae: 23.4202 - val_loss: nan - val_mae: nan\n",
      "Epoch 87/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3771 - mae: 23.3771 - val_loss: nan - val_mae: nan\n",
      "Epoch 88/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3437 - mae: 23.3437 - val_loss: nan - val_mae: nan\n",
      "Epoch 89/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3813 - mae: 23.3813 - val_loss: nan - val_mae: nan\n",
      "Epoch 90/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3471 - mae: 23.3471 - val_loss: nan - val_mae: nan\n",
      "Epoch 91/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3323 - mae: 23.3323 - val_loss: nan - val_mae: nan\n",
      "Epoch 92/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3725 - mae: 23.3725 - val_loss: nan - val_mae: nan\n",
      "Epoch 93/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3555 - mae: 23.3555 - val_loss: nan - val_mae: nan\n",
      "Epoch 94/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3860 - mae: 23.3860 - val_loss: nan - val_mae: nan\n",
      "Epoch 95/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3385 - mae: 23.3385 - val_loss: nan - val_mae: nan\n",
      "Epoch 96/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3535 - mae: 23.3535 - val_loss: nan - val_mae: nan\n",
      "Epoch 97/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3525 - mae: 23.3525 - val_loss: nan - val_mae: nan\n",
      "Epoch 98/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4030 - mae: 23.4030 - val_loss: nan - val_mae: nan\n",
      "Epoch 99/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3561 - mae: 23.3561 - val_loss: nan - val_mae: nan\n",
      "Epoch 100/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3602 - mae: 23.3602 - val_loss: nan - val_mae: nan\n",
      "Epoch 101/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4608 - mae: 23.4608 - val_loss: nan - val_mae: nan\n",
      "Epoch 102/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4499 - mae: 23.4499 - val_loss: nan - val_mae: nan\n",
      "Epoch 103/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3357 - mae: 23.3357 - val_loss: nan - val_mae: nan\n",
      "Epoch 104/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3397 - mae: 23.3397 - val_loss: nan - val_mae: nan\n",
      "Epoch 105/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3494 - mae: 23.3494 - val_loss: nan - val_mae: nan\n",
      "Epoch 106/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3731 - mae: 23.3731 - val_loss: nan - val_mae: nan\n",
      "Epoch 107/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3635 - mae: 23.3635 - val_loss: nan - val_mae: nan\n",
      "Epoch 108/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3827 - mae: 23.3827 - val_loss: nan - val_mae: nan\n",
      "Epoch 109/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3694 - mae: 23.3694 - val_loss: nan - val_mae: nan\n",
      "Epoch 110/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3504 - mae: 23.3504 - val_loss: nan - val_mae: nan\n",
      "Epoch 111/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4016 - mae: 23.4016 - val_loss: nan - val_mae: nan\n",
      "Epoch 112/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3794 - mae: 23.3794 - val_loss: nan - val_mae: nan\n",
      "Epoch 113/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3547 - mae: 23.3547 - val_loss: nan - val_mae: nan\n",
      "Epoch 114/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3533 - mae: 23.3533 - val_loss: nan - val_mae: nan\n",
      "Epoch 115/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3563 - mae: 23.3563 - val_loss: nan - val_mae: nan\n",
      "Epoch 116/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3366 - mae: 23.3366 - val_loss: nan - val_mae: nan\n",
      "Epoch 117/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3906 - mae: 23.3906 - val_loss: nan - val_mae: nan\n",
      "Epoch 118/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3770 - mae: 23.3770 - val_loss: nan - val_mae: nan\n",
      "Epoch 119/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3988 - mae: 23.3988 - val_loss: nan - val_mae: nan\n",
      "Epoch 120/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3913 - mae: 23.3913 - val_loss: nan - val_mae: nan\n",
      "Epoch 121/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3354 - mae: 23.3354 - val_loss: nan - val_mae: nan\n",
      "Epoch 122/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.4040 - mae: 23.4040 - val_loss: nan - val_mae: nan\n",
      "Epoch 123/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4043 - mae: 23.4043 - val_loss: nan - val_mae: nan\n",
      "Epoch 124/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3869 - mae: 23.3869 - val_loss: nan - val_mae: nan\n",
      "Epoch 125/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4010 - mae: 23.4010 - val_loss: nan - val_mae: nan\n",
      "Epoch 126/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3598 - mae: 23.3598 - val_loss: nan - val_mae: nan\n",
      "Epoch 127/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3845 - mae: 23.3845 - val_loss: nan - val_mae: nan\n",
      "Epoch 128/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3560 - mae: 23.3560 - val_loss: nan - val_mae: nan\n",
      "Epoch 129/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4068 - mae: 23.4068 - val_loss: nan - val_mae: nan\n",
      "Epoch 130/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4342 - mae: 23.4342 - val_loss: nan - val_mae: nan\n",
      "Epoch 131/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3478 - mae: 23.3478 - val_loss: nan - val_mae: nan\n",
      "Epoch 132/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3982 - mae: 23.3982 - val_loss: nan - val_mae: nan\n",
      "Epoch 133/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3359 - mae: 23.3359 - val_loss: nan - val_mae: nan\n",
      "Epoch 134/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3855 - mae: 23.3855 - val_loss: nan - val_mae: nan\n",
      "Epoch 135/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3534 - mae: 23.3534 - val_loss: nan - val_mae: nan\n",
      "Epoch 136/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3717 - mae: 23.3717 - val_loss: nan - val_mae: nan\n",
      "Epoch 137/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4230 - mae: 23.4230 - val_loss: nan - val_mae: nan\n",
      "Epoch 138/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3743 - mae: 23.3743 - val_loss: nan - val_mae: nan\n",
      "Epoch 139/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3842 - mae: 23.3842 - val_loss: nan - val_mae: nan\n",
      "Epoch 140/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3352 - mae: 23.3352 - val_loss: nan - val_mae: nan\n",
      "Epoch 141/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3463 - mae: 23.3463 - val_loss: nan - val_mae: nan\n",
      "Epoch 142/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3835 - mae: 23.3835 - val_loss: nan - val_mae: nan\n",
      "Epoch 143/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3707 - mae: 23.3707 - val_loss: nan - val_mae: nan\n",
      "Epoch 144/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3538 - mae: 23.3538 - val_loss: nan - val_mae: nan\n",
      "Epoch 145/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4058 - mae: 23.4058 - val_loss: nan - val_mae: nan\n",
      "Epoch 146/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4004 - mae: 23.4004 - val_loss: nan - val_mae: nan\n",
      "Epoch 147/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3642 - mae: 23.3642 - val_loss: nan - val_mae: nan\n",
      "Epoch 148/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3596 - mae: 23.3596 - val_loss: nan - val_mae: nan\n",
      "Epoch 149/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3503 - mae: 23.3503 - val_loss: nan - val_mae: nan\n",
      "Epoch 150/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3433 - mae: 23.3433 - val_loss: nan - val_mae: nan\n",
      "Epoch 151/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3488 - mae: 23.3488 - val_loss: nan - val_mae: nan\n",
      "Epoch 152/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4066 - mae: 23.4066 - val_loss: nan - val_mae: nan\n",
      "Epoch 153/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3677 - mae: 23.3677 - val_loss: nan - val_mae: nan\n",
      "Epoch 154/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3865 - mae: 23.3865 - val_loss: nan - val_mae: nan\n",
      "Epoch 155/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3361 - mae: 23.3361 - val_loss: nan - val_mae: nan\n",
      "Epoch 156/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3729 - mae: 23.3729 - val_loss: nan - val_mae: nan\n",
      "Epoch 157/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3759 - mae: 23.3759 - val_loss: nan - val_mae: nan\n",
      "Epoch 158/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3354 - mae: 23.3354 - val_loss: nan - val_mae: nan\n",
      "Epoch 159/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4816 - mae: 23.4816 - val_loss: nan - val_mae: nan\n",
      "Epoch 160/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3788 - mae: 23.3788 - val_loss: nan - val_mae: nan\n",
      "Epoch 161/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3528 - mae: 23.3528 - val_loss: nan - val_mae: nan\n",
      "Epoch 162/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4279 - mae: 23.4279 - val_loss: nan - val_mae: nan\n",
      "Epoch 163/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4490 - mae: 23.4490 - val_loss: nan - val_mae: nan\n",
      "Epoch 164/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3555 - mae: 23.3555 - val_loss: nan - val_mae: nan\n",
      "Epoch 165/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3515 - mae: 23.3515 - val_loss: nan - val_mae: nan\n",
      "Epoch 166/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3705 - mae: 23.3705 - val_loss: nan - val_mae: nan\n",
      "Epoch 167/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3361 - mae: 23.3361 - val_loss: nan - val_mae: nan\n",
      "Epoch 168/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3467 - mae: 23.3467 - val_loss: nan - val_mae: nan\n",
      "Epoch 169/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3618 - mae: 23.3618 - val_loss: nan - val_mae: nan\n",
      "Epoch 170/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4191 - mae: 23.4191 - val_loss: nan - val_mae: nan\n",
      "Epoch 171/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4018 - mae: 23.4018 - val_loss: nan - val_mae: nan\n",
      "Epoch 172/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3759 - mae: 23.3759 - val_loss: nan - val_mae: nan\n",
      "Epoch 173/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3417 - mae: 23.3417 - val_loss: nan - val_mae: nan\n",
      "Epoch 174/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3587 - mae: 23.3587 - val_loss: nan - val_mae: nan\n",
      "Epoch 175/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3800 - mae: 23.3800 - val_loss: nan - val_mae: nan\n",
      "Epoch 176/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4032 - mae: 23.4032 - val_loss: nan - val_mae: nan\n",
      "Epoch 177/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3445 - mae: 23.3445 - val_loss: nan - val_mae: nan\n",
      "Epoch 178/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4140 - mae: 23.4140 - val_loss: nan - val_mae: nan\n",
      "Epoch 179/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3839 - mae: 23.3839 - val_loss: nan - val_mae: nan\n",
      "Epoch 180/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3823 - mae: 23.3823 - val_loss: nan - val_mae: nan\n",
      "Epoch 181/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3947 - mae: 23.3947 - val_loss: nan - val_mae: nan\n",
      "Epoch 182/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3685 - mae: 23.3685 - val_loss: nan - val_mae: nan\n",
      "Epoch 183/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3349 - mae: 23.3349 - val_loss: nan - val_mae: nan\n",
      "Epoch 184/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3432 - mae: 23.3432 - val_loss: nan - val_mae: nan\n",
      "Epoch 185/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3448 - mae: 23.3448 - val_loss: nan - val_mae: nan\n",
      "Epoch 186/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3434 - mae: 23.3434 - val_loss: nan - val_mae: nan\n",
      "Epoch 187/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3568 - mae: 23.3568 - val_loss: nan - val_mae: nan\n",
      "Epoch 188/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3777 - mae: 23.3777 - val_loss: nan - val_mae: nan\n",
      "Epoch 189/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3663 - mae: 23.3663 - val_loss: nan - val_mae: nan\n",
      "Epoch 190/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4188 - mae: 23.4188 - val_loss: nan - val_mae: nan\n",
      "Epoch 191/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3588 - mae: 23.3588 - val_loss: nan - val_mae: nan\n",
      "Epoch 192/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3537 - mae: 23.3537 - val_loss: nan - val_mae: nan\n",
      "Epoch 193/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3353 - mae: 23.3353 - val_loss: nan - val_mae: nan\n",
      "Epoch 194/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3647 - mae: 23.3647 - val_loss: nan - val_mae: nan\n",
      "Epoch 195/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3640 - mae: 23.3640 - val_loss: nan - val_mae: nan\n",
      "Epoch 196/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3762 - mae: 23.3762 - val_loss: nan - val_mae: nan\n",
      "Epoch 197/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3582 - mae: 23.3582 - val_loss: nan - val_mae: nan\n",
      "Epoch 198/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3744 - mae: 23.3744 - val_loss: nan - val_mae: nan\n",
      "Epoch 199/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3516 - mae: 23.3516 - val_loss: nan - val_mae: nan\n",
      "Epoch 200/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.4335 - mae: 23.4335 - val_loss: nan - val_mae: nan\n",
      "Epoch 201/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3728 - mae: 23.3728 - val_loss: nan - val_mae: nan\n",
      "Epoch 202/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3353 - mae: 23.3353 - val_loss: nan - val_mae: nan\n",
      "Epoch 203/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3495 - mae: 23.3495 - val_loss: nan - val_mae: nan\n",
      "Epoch 204/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3713 - mae: 23.3713 - val_loss: nan - val_mae: nan\n",
      "Epoch 205/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3531 - mae: 23.3531 - val_loss: nan - val_mae: nan\n",
      "Epoch 206/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3783 - mae: 23.3783 - val_loss: nan - val_mae: nan\n",
      "Epoch 207/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3439 - mae: 23.3439 - val_loss: nan - val_mae: nan\n",
      "Epoch 208/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4079 - mae: 23.4079 - val_loss: nan - val_mae: nan\n",
      "Epoch 209/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3791 - mae: 23.3791 - val_loss: nan - val_mae: nan\n",
      "Epoch 210/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3800 - mae: 23.3800 - val_loss: nan - val_mae: nan\n",
      "Epoch 211/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3654 - mae: 23.3654 - val_loss: nan - val_mae: nan\n",
      "Epoch 212/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3817 - mae: 23.3817 - val_loss: nan - val_mae: nan\n",
      "Epoch 213/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3816 - mae: 23.3816 - val_loss: nan - val_mae: nan\n",
      "Epoch 214/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3365 - mae: 23.3365 - val_loss: nan - val_mae: nan\n",
      "Epoch 215/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3988 - mae: 23.3988 - val_loss: nan - val_mae: nan\n",
      "Epoch 216/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3822 - mae: 23.3822 - val_loss: nan - val_mae: nan\n",
      "Epoch 217/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4057 - mae: 23.4057 - val_loss: nan - val_mae: nan\n",
      "Epoch 218/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3753 - mae: 23.3753 - val_loss: nan - val_mae: nan\n",
      "Epoch 219/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4044 - mae: 23.4044 - val_loss: nan - val_mae: nan\n",
      "Epoch 220/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3503 - mae: 23.3503 - val_loss: nan - val_mae: nan\n",
      "Epoch 221/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3872 - mae: 23.3872 - val_loss: nan - val_mae: nan\n",
      "Epoch 222/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3812 - mae: 23.3812 - val_loss: nan - val_mae: nan\n",
      "Epoch 223/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4348 - mae: 23.4348 - val_loss: nan - val_mae: nan\n",
      "Epoch 224/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4143 - mae: 23.4143 - val_loss: nan - val_mae: nan\n",
      "Epoch 225/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3419 - mae: 23.3419 - val_loss: nan - val_mae: nan\n",
      "Epoch 226/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3802 - mae: 23.3802 - val_loss: nan - val_mae: nan\n",
      "Epoch 227/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3590 - mae: 23.3590 - val_loss: nan - val_mae: nan\n",
      "Epoch 228/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3833 - mae: 23.3833 - val_loss: nan - val_mae: nan\n",
      "Epoch 229/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3897 - mae: 23.3897 - val_loss: nan - val_mae: nan\n",
      "Epoch 230/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4009 - mae: 23.4009 - val_loss: nan - val_mae: nan\n",
      "Epoch 231/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3703 - mae: 23.3703 - val_loss: nan - val_mae: nan\n",
      "Epoch 232/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3954 - mae: 23.3954 - val_loss: nan - val_mae: nan\n",
      "Epoch 233/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3527 - mae: 23.3527 - val_loss: nan - val_mae: nan\n",
      "Epoch 234/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4304 - mae: 23.4304 - val_loss: nan - val_mae: nan\n",
      "Epoch 235/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3914 - mae: 23.3914 - val_loss: nan - val_mae: nan\n",
      "Epoch 236/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3956 - mae: 23.3956 - val_loss: nan - val_mae: nan\n",
      "Epoch 237/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3681 - mae: 23.3681 - val_loss: nan - val_mae: nan\n",
      "Epoch 238/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3737 - mae: 23.3737 - val_loss: nan - val_mae: nan\n",
      "Epoch 239/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3690 - mae: 23.3690 - val_loss: nan - val_mae: nan\n",
      "Epoch 240/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3843 - mae: 23.3843 - val_loss: nan - val_mae: nan\n",
      "Epoch 241/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3947 - mae: 23.3947 - val_loss: nan - val_mae: nan\n",
      "Epoch 242/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3575 - mae: 23.3575 - val_loss: nan - val_mae: nan\n",
      "Epoch 243/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3768 - mae: 23.3768 - val_loss: nan - val_mae: nan\n",
      "Epoch 244/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3906 - mae: 23.3906 - val_loss: nan - val_mae: nan\n",
      "Epoch 245/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3872 - mae: 23.3872 - val_loss: nan - val_mae: nan\n",
      "Epoch 246/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3810 - mae: 23.3810 - val_loss: nan - val_mae: nan\n",
      "Epoch 247/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4173 - mae: 23.4173 - val_loss: nan - val_mae: nan\n",
      "Epoch 248/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3593 - mae: 23.3593 - val_loss: nan - val_mae: nan\n",
      "Epoch 249/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3349 - mae: 23.3349 - val_loss: nan - val_mae: nan\n",
      "Epoch 250/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3578 - mae: 23.3578 - val_loss: nan - val_mae: nan\n",
      "Epoch 251/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3761 - mae: 23.3761 - val_loss: nan - val_mae: nan\n",
      "Epoch 252/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3702 - mae: 23.3702 - val_loss: nan - val_mae: nan\n",
      "Epoch 253/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4113 - mae: 23.4113 - val_loss: nan - val_mae: nan\n",
      "Epoch 254/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3617 - mae: 23.3617 - val_loss: nan - val_mae: nan\n",
      "Epoch 255/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3487 - mae: 23.3487 - val_loss: nan - val_mae: nan\n",
      "Epoch 256/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4091 - mae: 23.4091 - val_loss: nan - val_mae: nan\n",
      "Epoch 257/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3616 - mae: 23.3616 - val_loss: nan - val_mae: nan\n",
      "Epoch 258/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3806 - mae: 23.3806 - val_loss: nan - val_mae: nan\n",
      "Epoch 259/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3540 - mae: 23.3540 - val_loss: nan - val_mae: nan\n",
      "Epoch 260/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3555 - mae: 23.3555 - val_loss: nan - val_mae: nan\n",
      "Epoch 261/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4398 - mae: 23.4398 - val_loss: nan - val_mae: nan\n",
      "Epoch 262/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3357 - mae: 23.3357 - val_loss: nan - val_mae: nan\n",
      "Epoch 263/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3790 - mae: 23.3790 - val_loss: nan - val_mae: nan\n",
      "Epoch 264/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3609 - mae: 23.3609 - val_loss: nan - val_mae: nan\n",
      "Epoch 265/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3939 - mae: 23.3939 - val_loss: nan - val_mae: nan\n",
      "Epoch 266/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3730 - mae: 23.3730 - val_loss: nan - val_mae: nan\n",
      "Epoch 267/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3731 - mae: 23.3731 - val_loss: nan - val_mae: nan\n",
      "Epoch 268/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3607 - mae: 23.3607 - val_loss: nan - val_mae: nan\n",
      "Epoch 269/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3560 - mae: 23.3560 - val_loss: nan - val_mae: nan\n",
      "Epoch 270/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4064 - mae: 23.4064 - val_loss: nan - val_mae: nan\n",
      "Epoch 271/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3677 - mae: 23.3677 - val_loss: nan - val_mae: nan\n",
      "Epoch 272/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3933 - mae: 23.3933 - val_loss: nan - val_mae: nan\n",
      "Epoch 273/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3745 - mae: 23.3745 - val_loss: nan - val_mae: nan\n",
      "Epoch 274/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3812 - mae: 23.3812 - val_loss: nan - val_mae: nan\n",
      "Epoch 275/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4202 - mae: 23.4202 - val_loss: nan - val_mae: nan\n",
      "Epoch 276/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4231 - mae: 23.4231 - val_loss: nan - val_mae: nan\n",
      "Epoch 277/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3880 - mae: 23.3880 - val_loss: nan - val_mae: nan\n",
      "Epoch 278/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4013 - mae: 23.4013 - val_loss: nan - val_mae: nan\n",
      "Epoch 279/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4003 - mae: 23.4003 - val_loss: nan - val_mae: nan\n",
      "Epoch 280/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.4231 - mae: 23.4231 - val_loss: nan - val_mae: nan\n",
      "Epoch 281/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3913 - mae: 23.3913 - val_loss: nan - val_mae: nan\n",
      "Epoch 282/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3537 - mae: 23.3537 - val_loss: nan - val_mae: nan\n",
      "Epoch 283/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3744 - mae: 23.3744 - val_loss: nan - val_mae: nan\n",
      "Epoch 284/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3915 - mae: 23.3915 - val_loss: nan - val_mae: nan\n",
      "Epoch 285/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3809 - mae: 23.3809 - val_loss: nan - val_mae: nan\n",
      "Epoch 286/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23.3914 - mae: 23.3914 - val_loss: nan - val_mae: nan\n",
      "Epoch 287/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.4004 - mae: 23.4004 - val_loss: nan - val_mae: nan\n",
      "Epoch 288/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3601 - mae: 23.3601 - val_loss: nan - val_mae: nan\n",
      "Epoch 289/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3558 - mae: 23.3558 - val_loss: nan - val_mae: nan\n",
      "Epoch 290/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4188 - mae: 23.4188 - val_loss: nan - val_mae: nan\n",
      "Epoch 291/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3980 - mae: 23.3980 - val_loss: nan - val_mae: nan\n",
      "Epoch 292/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3681 - mae: 23.3681 - val_loss: nan - val_mae: nan\n",
      "Epoch 293/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3774 - mae: 23.3774 - val_loss: nan - val_mae: nan\n",
      "Epoch 294/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3789 - mae: 23.3789 - val_loss: nan - val_mae: nan\n",
      "Epoch 295/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.3778 - mae: 23.3778 - val_loss: nan - val_mae: nan\n",
      "Epoch 296/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4627 - mae: 23.4627 - val_loss: nan - val_mae: nan\n",
      "Epoch 297/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3747 - mae: 23.3747 - val_loss: nan - val_mae: nan\n",
      "Epoch 298/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4109 - mae: 23.4109 - val_loss: nan - val_mae: nan\n",
      "Epoch 299/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4028 - mae: 23.4028 - val_loss: nan - val_mae: nan\n",
      "Epoch 300/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.3391 - mae: 23.3391 - val_loss: nan - val_mae: nan\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = tts(X, Y)\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=Y_train,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    batch_size=5,\n",
    "    epochs=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff307959bb0>]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUTElEQVR4nO3db4xc1XnH8e+zBoyJIcH2mjq2wTZxpRLU5o8FKyWKqpIWJ61q+gLJkdL4BZKliKiJ1KqCRm2TF0i0UqM2L4JEkwgnTYMsJS1uEtQiN1HUCuwsCWAbQnBwAg4uNnYSDGkN9j59MWd3Z+furnfN7s7Ome9HGu6dM/funqOLf/fuOXfOjcxEktQfBrpdAUnSwjH0JamPGPqS1EcMfUnqI4a+JPWRi7pdgfNZtWpVbtiwodvVkKSe8uijj76UmYOd5Ys+9Dds2MDw8HC3qyFJPSUifjpZud07ktRHDH1J6iOGviT1EUNfkvqIoS9JfcTQl6Q+YuhLUh+pNvTv++8j/NvjL3S7GpK0qFQb+l/Z9xwPHjzW7WpI0qJSbehHwMhIt2shSYtLvaFPkPhUMElqV2/oB/gkSEmaqOLQD0YMfUmaoNrQHwjA7h1JmqDa0I/AK31J6lBt6A9EkHbqS9IE1YZ+4JW+JHWqNvSJsEdfkjpUG/oDgd07ktSh2tAPvE9fkjpVG/oD4TdyJalTtaHv3DuS1FRx6HulL0md6g19vGVTkjrVG/qBszBIUodqQ9+BXElqqjb0nXtHkpqqDX3n3pGkpmpDH7zSl6RO1YZ+OPeOJDVUG/oDzsMgSQ3Vhr736UtSU7Wh7y2bktRUbeg7944kNc049CNiSUT8ICK+Ud6viIiHIuKZsryybds7I+JwRDwdETe3lb87Ig6Uzz4bETG3zZlQX6/zJanDbK70Pw481fb+DmBvZm4G9pb3RMR1wHbg7cBW4HMRsaTscw+wE9hcXlvfUO2n0RrHNfYlqd2MQj8i1gG/D3y+rXgbsKus7wJuaSu/PzPPZOYR4DBwQ0SsAa7IzIezlcZfattnzkV4844kdZrplf7fA38OtPeSX5WZxwDKcnUpXws837bd0VK2tqx3ljdExM6IGI6I4RMnTsywihM5kCtJTecN/Yj4A+B4Zj46w585WT99TlPeLMy8NzO3ZOaWwcHBGf7ajko4944kNVw0g23eA/xhRHwQuBS4IiL+CXgxItZk5rHSdXO8bH8UWN+2/zrghVK+bpLyeRHOvSNJDee90s/MOzNzXWZuoDVA+5+Z+WFgD7CjbLYDeKCs7wG2R8TSiNhIa8B2f+kCOh0RQ+WunY+07TPn/EKuJDXN5Ep/KncDuyPiNuA54FaAzDwUEbuBJ4GzwO2Zea7s81HgPmAZ8GB5zYsBb9mUpIZZhX5mfgf4Tlk/Cdw0xXZ3AXdNUj4MXD/bSl6IVp++sS9J7er9Ri5270hSp2pD31s2Jamp2tDHuXckqaHa0B+Yv2l9JKlnVRv6rfn07d6RpHb1hr5z70hSQ7Wh70CuJDVVG/rOvSNJTRWHfti9I0kd6g19fIiKJHWqNvSde0eSmqoNfefekaSmekMfb9mUpE71hr4PUZGkhopD3yt9SepUbeg7kCtJTdWGvnPvSFJTtaE/MOCXsySpU7Wh75W+JDVVG/oE9ulLUodqQ38gTH1J6lRt6Nu9I0lN1Ya+t2xKUlO1oe/cO5LUVHHoe8umJHWqN/TL0vl3JGlcvaFfUt/Ml6Rx1Yb+QEl9M1+SxlUb+qPdOw7mStK4akN/YKBc6Zv5kjSm2tAf5ZW+JI2rNvRHB3IlSeOqDf2xgVwv9CVpzHlDPyIujYj9EfF4RByKiE+X8hUR8VBEPFOWV7btc2dEHI6IpyPi5rbyd0fEgfLZZyPm73rcgVxJaprJlf4Z4Hcy87eAdwBbI2IIuAPYm5mbgb3lPRFxHbAdeDuwFfhcRCwpP+seYCewuby2zl1TJvKWTUlqOm/oZ8sr5e3F5ZXANmBXKd8F3FLWtwH3Z+aZzDwCHAZuiIg1wBWZ+XC2vib7pbZ95tzo3xBe6UvSuBn16UfEkoh4DDgOPJSZ+4CrMvMYQFmuLpuvBZ5v2/1oKVtb1jvL50XYpy9JDTMK/cw8l5nvANbRumq/fprNJ+unz2nKmz8gYmdEDEfE8IkTJ2ZSxSkr4dw7kjRuVnfvZOYvgO/Q6ot/sXTZUJbHy2ZHgfVtu60DXijl6yYpn+z33JuZWzJzy+Dg4GyqOMa5dySpaSZ37wxGxFvK+jLg/cAPgT3AjrLZDuCBsr4H2B4RSyNiI60B2/2lC+h0RAyVu3Y+0rbPnHMgV5KaLprBNmuAXeUOnAFgd2Z+IyIeBnZHxG3Ac8CtAJl5KCJ2A08CZ4HbM/Nc+VkfBe4DlgEPlte8cCBXkprOG/qZ+QTwzknKTwI3TbHPXcBdk5QPA9ONB8wZB3Ilqanab+Q6kCtJTdWGvn36ktRUbeh7944kNdUb+mXpQK4kjas29O3ekaSmakN/9FJ/ZMTYl6RR1Yb+gE9RkaSGakPfPn1Jaqo39L17R5Iaqg19B3Ilqana0HfuHUlqqjj0nXtHkjrVG/pl6dw7kjSu2tC3T1+SmqoNfe/ekaSmekO/LB3IlaRx9Ya+A7mS1FBx6LeWXulL0rhqQ9+5dySpqdrQt09fkpqqDf2B0jIzX5LGVRv6gffpS1KnakMfB3IlqaHa0B/wlk1Jaqg29J17R5Kaqg19596RpKZqQz98MLokNdQb+mVp5EvSuHpD34FcSWqoOPRbSwdyJWlctaHvQK4kNVUb+s6yKUlN1Yb+gE/OkqSGakMf596RpIbzhn5ErI+Ib0fEUxFxKCI+XspXRMRDEfFMWV7Zts+dEXE4Ip6OiJvbyt8dEQfKZ5+NmL9J7+3ekaSmmVzpnwX+NDN/AxgCbo+I64A7gL2ZuRnYW95TPtsOvB3YCnwuIpaUn3UPsBPYXF5b57AtE4w9RMXMl6Qx5w39zDyWmd8v66eBp4C1wDZgV9lsF3BLWd8G3J+ZZzLzCHAYuCEi1gBXZObD2bqP8ktt+8w5H6IiSU2z6tOPiA3AO4F9wFWZeQxaJwZgddlsLfB8225HS9nast5ZPtnv2RkRwxExfOLEidlUcYyzbEpS04xDPyKWA18DPpGZL0+36SRlOU15szDz3szckplbBgcHZ1rFiZWwT1+SGmYU+hFxMa3A/0pmfr0Uv1i6bCjL46X8KLC+bfd1wAulfN0k5fPCLn1JaprJ3TsBfAF4KjM/0/bRHmBHWd8BPNBWvj0ilkbERloDtvtLF9DpiBgqP/MjbfvMubHHJZr6kjTmohls8x7gj4EDEfFYKfsL4G5gd0TcBjwH3AqQmYciYjfwJK07f27PzHNlv48C9wHLgAfLa144944kNZ039DPzv5i8Px7gpin2uQu4a5LyYeD62VTwQjn3jiQ1VfuNXAdyJamp2tB37h1Jaqo29Ed7pLzSl6Rx1Yb+/M3qI0m9q9rQ9xu5ktRUbeg7944kNVUb+l7pS1JTtaHvLZuS1FR96Bv5kjSu4tA39SWpU72hX5Z270jSuGpD37l3JKmp2tB3IFeSmqoPfTNfksbVG/pjD1Ex9SVpVLWhP+DNO5LUUG3oh9/IlaSGekO/LB3IlaRx1Ya+c+9IUlO1oY+3bEpSQ7WhP+BDVCSpodrQHx3I9UpfksbVG/plaeZL0rhqQ9+5dySpqdrQd+4dSWqqPvTNfEkaV2/oO/eOJDVUG/oDXulLUkO1oR8O5EpSQ72hX5YO5ErSuHpD3+4dSWqoOPQdyJWkTtWGPrQGc418SRp33tCPiC9GxPGIONhWtiIiHoqIZ8ryyrbP7oyIwxHxdETc3Fb+7og4UD77bIxeis+jiLBPX5LazORK/z5ga0fZHcDezNwM7C3viYjrgO3A28s+n4uIJWWfe4CdwOby6vyZc24g7NOXpHbnDf3M/C5wqqN4G7CrrO8Cbmkrvz8zz2TmEeAwcENErAGuyMyHs9XJ/qW2feZNEHbvSFKbC+3TvyozjwGU5epSvhZ4vm27o6VsbVnvLJ9UROyMiOGIGD5x4sQFVhEIb9mUpHZzPZA7WT99TlM+qcy8NzO3ZOaWwcHBC67MQEz3WySp/1xo6L9Yumwoy+Ol/Ciwvm27dcALpXzdJOXzKnAgV5LaXWjo7wF2lPUdwANt5dsjYmlEbKQ1YLu/dAGdjoihctfOR9r2mTcO5ErSRBedb4OI+Crw28CqiDgK/DVwN7A7Im4DngNuBcjMQxGxG3gSOAvcnpnnyo/6KK07gZYBD5bXvGrdsjnfv0WSesd5Qz8zPzTFRzdNsf1dwF2TlA8D18+qdm9Qq0vf1JekUVV/Izfs3pGkCSoP/XDuHUlqU3XoO/eOJE1Udeg7944kTVR16HvLpiRNVHXo49w7kjRB1aHfunvH2JekUVWHvt07kjRR1aHv3DuSNFHVoe+VviRNVHXoO/eOJE1Ueeg7944ktas+9M18SRpXd+g7kCtJE1Qd+s69I0kTVR36DuRK0kSVh77fyJWkdnWHPt6nL0ntqg79gQhv2ZSkNlWHvo9LlKSJ6g59b9mUpAmqDv2BgWD/kVP85b8e5JtPHOOlV850u0qS1FUXdbsC8+njN23mn/c/x9e+f5QvP/JTADavXs6Nm1YwtGklN25cyeDlS7tcS0laOLHYb2ncsmVLDg8Pv6Gf8fq5EQ787Jfse/YUjzx7kuGfnOLV184BcO3gmxjatLJ1Eti0gtWXXzoX1ZakroqIRzNzS6O8H0K/09lzIxx84WUeefZkOQn8nFfOnAVgUzkJ3Lix9dfAVVd4EpDUewz9aZw9N8KhchLYd+QU3ztyitOjJ4FVb5rQHfRrb/YkIGnxM/Rn4ey5EZ489vJYd9D+tpPAhpWXTegOWvPmZQtaN0maCUP/DTg3kjx1bLw7aN+RU5z+v9ZJ4JqVlzG0cSVD167gxo0reetbPAlI6j5Dfw61nwT2HTnFvmdP8nI5CVy94jKGNrVOAEPXrmStJwFJXWDoz6NzI8kP/2e8O2jfkVP88n9fB2D9imWtE8CmlQxtWsG6Ky/rcm0l9QNDfwGNjCRPv3h6rDto/5FT/PxXrZPA2rcsGzsBDG1ayfoVngQkzT1Dv4tGRpIfHT/NIz8+ySPPnmLfkZMTTgKjdwcNbVzJ+hXLiIgu11hSrzP0F5GRkeSZ46+UrqDWieDUq68B8NY3Xzp2Z9DQppVcveIyTwKSZs3QX8Qyk8PlJPBIGRc4WU4Ca9586dgXxYY2reSalZ4EJJ3fogn9iNgK/AOwBPh8Zt493fb9EPqdMpMfn3iFh0cHhp89NTZZ3FVXLB07Afz6VZezavklrFq+lDctrXoaJUmztChCPyKWAD8Cfhc4CnwP+FBmPjnVPv0Y+p1aJ4FXx+4MeuTZk5w4PXHG0IGAi5cMcMlFA1xSlgMRRLSeKwCtqaah9X70b4XRvxpi7D/NzyR1xzf/5L0svWjJBe07Vegv9OXhDcDhzHy2VOp+YBswZeirFb5vW72ct61ezoeHriEzOfLSq/z01K84+cprvPTKGV49c5bXzo3w2tnW6/VzI5wdSUYfHDZ6as/MtvXxz0ZP/mOXAIu710/qC8HcX3gtdOivBZ5ve38UuLFzo4jYCewEuPrqqxemZj0kItg0uJxNg8u7XRVJPWahH6Iy2WmrcU2Zmfdm5pbM3DI4OLgA1ZKk/rDQoX8UWN/2fh3wwgLXQZL61kKH/veAzRGxMSIuAbYDexa4DpLUtxa0Tz8zz0bEx4B/p3XL5hcz89BC1kGS+tmC39ydmd8CvrXQv1eStPDdO5KkLjL0JamPGPqS1EcW/YRrEXEC+OkF7r4KeGkOq9NNtmVxsi2LTy3tgDfWlmsys/FFp0Uf+m9ERAxPNvdEL7Iti5NtWXxqaQfMT1vs3pGkPmLoS1IfqT307+12BeaQbVmcbMviU0s7YB7aUnWfviRpotqv9CVJbQx9SeojVYZ+RGyNiKcj4nBE3NHt+sxWRPwkIg5ExGMRMVzKVkTEQxHxTFle2e16TiYivhgRxyPiYFvZlHWPiDvLcXo6Im7uTq0nN0VbPhURPyvH5rGI+GDbZ4u5Lesj4tsR8VREHIqIj5fynjs207Slp45NRFwaEfsj4vHSjk+X8vk9JplZ1YvW7J0/BjYBlwCPA9d1u16zbMNPgFUdZX8L3FHW7wD+ptv1nKLu7wPeBRw8X92B68rxWQpsLMdtSbfbcJ62fAr4s0m2XextWQO8q6xfTutZ1df14rGZpi09dWxoPVRqeVm/GNgHDM33ManxSn/sObyZ+Row+hzeXrcN2FXWdwG3dK8qU8vM7wKnOoqnqvs24P7MPJOZR4DDtI7fojBFW6ay2NtyLDO/X9ZPA0/Renxpzx2badoylUXZlmx5pby9uLySeT4mNYb+ZM/hne5/iMUogf+IiEfL84IBrsrMY9D6nx5Y3bXazd5Ude/VY/WxiHiidP+M/undM22JiA3AO2ldWfb0seloC/TYsYmIJRHxGHAceCgz5/2Y1Bj6M3oO7yL3nsx8F/AB4PaIeF+3KzRPevFY3QNcC7wDOAb8XSnvibZExHLga8AnMvPl6TadpGxRtWeStvTcscnMc5n5DlqPjr0hIq6fZvM5aUeNod/zz+HNzBfK8jjwL7T+hHsxItYAlOXx7tVw1qaqe88dq8x8sfxDHQH+kfE/rxd9WyLiYloh+ZXM/Hop7sljM1lbevnYZOYvgO8AW5nnY1Jj6Pf0c3gj4k0RcfnoOvB7wEFabdhRNtsBPNCdGl6Qqeq+B9geEUsjYiOwGdjfhfrN2Og/xuKPaB0bWORtiYgAvgA8lZmfafuo547NVG3ptWMTEYMR8Zayvgx4P/BD5vuYdHsEe55GxT9Ia0T/x8Anu12fWdZ9E60R+seBQ6P1B1YCe4FnynJFt+s6Rf2/SutP69dpXZncNl3dgU+W4/Q08IFu138GbfkycAB4ovwjXNMjbXkvra6AJ4DHyuuDvXhspmlLTx0b4DeBH5T6HgT+qpTP6zFxGgZJ6iM1du9IkqZg6EtSHzH0JamPGPqS1EcMfUnqI4a+JPURQ1+S+sj/A+JZpjf13ckBAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21096360398365a9f1d9967aa419e1cfc324a03085554bd8f42696e4d11fd526"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
