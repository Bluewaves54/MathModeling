{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports modules\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dense, InputLayer, BatchNormalization\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import format_ppm_x\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "num_features = ()\n",
    "num_prev_vals = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 1\n"
     ]
    }
   ],
   "source": [
    "data = format_ppm_x(pd.read_csv('../data/ppm.csv'), num_prev_vals)\n",
    "\n",
    "# X = np.array(data.iloc[:, data.columns != 0]).reshape(num_prev_vals*(63-num_prev_vals), 1)\n",
    "X = data.iloc[:, data.columns != 0]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "Y = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(num_prev_vals,1)))\n",
    "    # model.add(LSTM(128, activation='relu', dropout=0.05, return_sequences=True))\n",
    "    model.add(LSTM(64, activation='relu', dropout=0.1, return_sequences=True))\n",
    "    model.add(LSTM(16, activation='relu', dropout=0.05, return_sequences=True))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Dense(8, activation='relu'))\n",
    "    # model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.1,\n",
    "    momentum=0.6,\n",
    "    nesterov=True,\n",
    ")\n",
    "\n",
    "model.compile(optimizer='Adagrad', loss='mae', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 4s 69ms/step - loss: 361.7089 - mae: 361.7089 - val_loss: 367.9928 - val_mae: 367.9928\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 361.7020 - mae: 361.7020 - val_loss: 367.9867 - val_mae: 367.9867\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.6961 - mae: 361.6961 - val_loss: 367.9811 - val_mae: 367.9811\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.6898 - mae: 361.6898 - val_loss: 367.9753 - val_mae: 367.9753\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.6844 - mae: 361.6844 - val_loss: 367.9697 - val_mae: 367.9697\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 361.6783 - mae: 361.6783 - val_loss: 367.9641 - val_mae: 367.9641\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 361.6731 - mae: 361.6731 - val_loss: 367.9586 - val_mae: 367.9586\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 361.6679 - mae: 361.6679 - val_loss: 367.9536 - val_mae: 367.9536\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 361.6635 - mae: 361.6635 - val_loss: 367.9489 - val_mae: 367.9489\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 361.6587 - mae: 361.6587 - val_loss: 367.9444 - val_mae: 367.9444\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.6551 - mae: 361.6551 - val_loss: 367.9400 - val_mae: 367.9400\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.6504 - mae: 361.6504 - val_loss: 367.9358 - val_mae: 367.9358\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 361.6461 - mae: 361.6461 - val_loss: 367.9318 - val_mae: 367.9318\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 361.6426 - mae: 361.6426 - val_loss: 367.9279 - val_mae: 367.9279\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.6383 - mae: 361.6383 - val_loss: 367.9240 - val_mae: 367.9240\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.6350 - mae: 361.6350 - val_loss: 367.9203 - val_mae: 367.9203\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 361.6312 - mae: 361.6312 - val_loss: 367.9166 - val_mae: 367.9166\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 361.6273 - mae: 361.6273 - val_loss: 367.9130 - val_mae: 367.9130\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.6239 - mae: 361.6239 - val_loss: 367.9095 - val_mae: 367.9095\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.6205 - mae: 361.6205 - val_loss: 367.9060 - val_mae: 367.9060\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.6170 - mae: 361.6170 - val_loss: 367.9025 - val_mae: 367.9025\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.6137 - mae: 361.6137 - val_loss: 367.8991 - val_mae: 367.8991\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.6100 - mae: 361.6100 - val_loss: 367.8956 - val_mae: 367.8956\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 361.6074 - mae: 361.6074 - val_loss: 367.8923 - val_mae: 367.8923\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.6039 - mae: 361.6039 - val_loss: 367.8889 - val_mae: 367.8889\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.6005 - mae: 361.6005 - val_loss: 367.8856 - val_mae: 367.8856\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.5973 - mae: 361.5973 - val_loss: 367.8822 - val_mae: 367.8822\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 361.5938 - mae: 361.5938 - val_loss: 367.8788 - val_mae: 367.8788\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 361.5912 - mae: 361.5912 - val_loss: 367.8755 - val_mae: 367.8755\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.5877 - mae: 361.5877 - val_loss: 367.8723 - val_mae: 367.8723\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.5842 - mae: 361.5842 - val_loss: 367.8689 - val_mae: 367.8689\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.5812 - mae: 361.5812 - val_loss: 367.8656 - val_mae: 367.8656\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 361.5775 - mae: 361.5775 - val_loss: 367.8623 - val_mae: 367.8623\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 361.5747 - mae: 361.5747 - val_loss: 367.8591 - val_mae: 367.8591\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 361.5707 - mae: 361.5707 - val_loss: 367.8558 - val_mae: 367.8558\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 361.5685 - mae: 361.5685 - val_loss: 367.8526 - val_mae: 367.8526\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 361.5656 - mae: 361.5656 - val_loss: 367.8494 - val_mae: 367.8494\n",
      "Epoch 38/300\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 359.5463 - mae: 359.5463"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ayushpal/Coding/MachineLearning/MathModeling/code/ppm_LSTM.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ayushpal/Coding/MachineLearning/MathModeling/code/ppm_LSTM.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_train, X_test, Y_train, Y_test \u001b[39m=\u001b[39m tts(X, Y, train_size\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ayushpal/Coding/MachineLearning/MathModeling/code/ppm_LSTM.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ayushpal/Coding/MachineLearning/MathModeling/code/ppm_LSTM.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     x\u001b[39m=\u001b[39;49mX_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ayushpal/Coding/MachineLearning/MathModeling/code/ppm_LSTM.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     y\u001b[39m=\u001b[39;49mY_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ayushpal/Coding/MachineLearning/MathModeling/code/ppm_LSTM.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(X_test, Y_test),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ayushpal/Coding/MachineLearning/MathModeling/code/ppm_LSTM.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ayushpal/Coding/MachineLearning/MathModeling/code/ppm_LSTM.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ayushpal/Coding/MachineLearning/MathModeling/code/ppm_LSTM.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = tts(X, Y, train_size=0.8)\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=Y_train,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    batch_size=5,\n",
    "    epochs=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff307959bb0>]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21096360398365a9f1d9967aa419e1cfc324a03085554bd8f42696e4d11fd526"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
